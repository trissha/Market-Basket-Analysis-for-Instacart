{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Marketing_FP_grp15.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z15xOqF2YoDS",
        "outputId": "6380263d-1874-4c82-f143-f3087a295c14"
      },
      "source": [
        "!pip install apyori"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting apyori\n",
            "  Downloading https://files.pythonhosted.org/packages/5e/62/5ffde5c473ea4b033490617ec5caa80d59804875ad3c3c57c0976533a21a/apyori-1.1.2.tar.gz\n",
            "Building wheels for collected packages: apyori\n",
            "  Building wheel for apyori (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for apyori: filename=apyori-1.1.2-cp36-none-any.whl size=5975 sha256=45216ce22b500320cffd83cac2234bbc78e0bd30af9e24b46056b9916b6fecd1\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/92/bb/474bbadbc8c0062b9eb168f69982a0443263f8ab1711a8cad0\n",
            "Successfully built apyori\n",
            "Installing collected packages: apyori\n",
            "Successfully installed apyori-1.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcUb6q4sRh7_"
      },
      "source": [
        "import os \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from apyori import apriori\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "from itertools import combinations\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "BuuNLAVWRh8I",
        "outputId": "a7817e28-18ed-4d0d-ffae-0f4fc73162d0"
      },
      "source": [
        "# Aisle Dataset\n",
        "aisles = pd.read_csv('aisles.csv')\n",
        "aisles.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-910d96fb2296>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Aisle Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maisles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'aisles.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0maisles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'aisles.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxTFK_XGRh8L"
      },
      "source": [
        "# Checking null value\n",
        "aisles.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiBGCZAnRh8L"
      },
      "source": [
        "# Department dataset\n",
        "department = pd.read_csv('departments.csv')\n",
        "department.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WAp1HUPRh8M"
      },
      "source": [
        "# Checking null value\n",
        "department.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqhU3JjVRh8N"
      },
      "source": [
        "# Product dataset\n",
        "product = pd.read_csv('products.csv')\n",
        "product.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v8-3zmxRh8N"
      },
      "source": [
        "# checking null value\n",
        "product.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNq_uouzRh8O"
      },
      "source": [
        "#Order dataset\n",
        "order = pd.read_csv('orders.csv')\n",
        "order.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUYF2a2lRh8O"
      },
      "source": [
        "# checking null values (NaN Represents order placed only one time)\n",
        "order.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX58nlU6Rh8P"
      },
      "source": [
        "# order product prior dataset\n",
        "oproduct = pd.read_csv('order_products__prior.csv')\n",
        "oproduct.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2sn85G9Rh8P"
      },
      "source": [
        "# checking null value\n",
        "oproduct.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYEumNgCRh8P"
      },
      "source": [
        "oproduct_t = pd.read_csv('order_products__train.csv')\n",
        "oproduct_t.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zbX1TlBRh8Q"
      },
      "source": [
        "## Number of orders by days of week"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBTXMRAhRh8Q"
      },
      "source": [
        "# Order in days of week\n",
        "ordersdow = order.order_dow.value_counts()\n",
        "ordersdow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPsrU5OnRh8Q"
      },
      "source": [
        "# Graph for number of orders by days of week\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(ordersdow.index, ordersdow)\n",
        "ax.set_title('Number of orders by days of week')\n",
        "ax.set_xlabel('day of week')\n",
        "ax.set_ylabel('number of orders')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcti91EkRh8R"
      },
      "source": [
        "# Taking product id and product name from product dataset\n",
        "products_name = {x: y for x, y in zip(product.product_id, product.product_name)}\n",
        "print(products_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gPXKrWeRh8R"
      },
      "source": [
        "#Merging 2 data frame(Order product and products name) into new\n",
        "oproduct_name = oproduct.copy()\n",
        "oproduct_name['product_name'] = oproduct_name.product_id.map(lambda x: products_name[x])\n",
        "oproduct_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7I4Can1Rh8R"
      },
      "source": [
        "# 0 represents product ordered first time and 1 indicated product reordered\n",
        "reordered = pd.crosstab(oproduct_name.product_name, oproduct_name.reordered)\n",
        "reordered.sort_values(by = 0, ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqGSMIN4Rh8S"
      },
      "source": [
        "# Values in Percentage FTP: first time purchased RP: Re purchased\n",
        "reordered['total'] = reordered.sum(axis = 1)\n",
        "reordered['FTP'] = reordered[0] / reordered['total']\n",
        "reordered['RP'] = reordered[1] / reordered['total']\n",
        "reordered.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1fmXdJ0Rh8S"
      },
      "source": [
        "# 100 means only purchased first time not purchased again\n",
        "reordered.sort_values(by = ['FTP', 'total'], ascending = False)[['FTP', 'total']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcslcMhJRh8S"
      },
      "source": [
        "# Percentage of re purchased items\n",
        "reordered.sort_values(by = ['RP', 'total'], ascending = False)[['RP', 'total']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1azmYw4fRh8S"
      },
      "source": [
        "# Products that ordered most\n",
        "reordered.total.sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16aTYG9LRh8T"
      },
      "source": [
        "# first param total product ordered second param total product\n",
        "porder = sorted(oproduct.product_id.unique())\n",
        "print(len(porder), len(product))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CT8hH4RRh8T"
      },
      "source": [
        "# Products that never been ordered\n",
        "pnotorder = list(product.product_id[~product.product_id.isin(porder)])\n",
        "[products_name[product] for product in pnotorder]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53a7h_jfRh8T"
      },
      "source": [
        "# Feature engineering\n",
        "### Predicting whether a product will be reordered or not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JUO_KGHRh8T"
      },
      "source": [
        "# Merging order products, product, department dataset\n",
        "merg = pd.merge(oproduct, order, on='order_id', how='left')\n",
        "merg.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hKxNtDFRh8T"
      },
      "source": [
        "merg1 = pd.merge(merg, product, on='product_id', how = 'left')\n",
        "merg1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av7u-P0gRh8U"
      },
      "source": [
        "mergf = pd.merge(merg1, department, on='department_id',how='left')\n",
        "mergf.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNFrr-H9Rh8U"
      },
      "source": [
        "#Getting the total items using the entire dataset \n",
        "mergf['total_items'] = merg1.groupby('user_id').size().astype(np.int16)\n",
        "mergf['total_items'] = mergf['total_items'].replace(np.nan, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiTbDmCqRh8U"
      },
      "source": [
        "del mergf['eval_set']\n",
        "del mergf['add_to_cart_order']\n",
        "del mergf['days_since_prior_order']\n",
        "del mergf['user_id']\n",
        "del mergf['product_name']\n",
        "del mergf['department']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esS1JoknRh8V"
      },
      "source": [
        "mergf.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okdowtjaRh8V"
      },
      "source": [
        "# Response variable\n",
        "y=mergf['reordered']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFT6zUyiRh8V"
      },
      "source": [
        "del mergf['reordered']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsWIXM0VRh8W"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(mergf, y, test_size=0.20, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zEEF2rXRh8W"
      },
      "source": [
        "### naive bayes model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi2wVgiPRh8X"
      },
      "source": [
        "# Fitting classifier to the Training set\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "# Predicting the Test set results \n",
        "y_pred = classifier.predict(X_test)\n",
        "# Evaluate the results\n",
        "from sklearn.metrics import accuracy_score\n",
        "score1 = accuracy_score(y_test,y_pred)\n",
        "print(\"Accuracy is \",round(score1*100,2),\"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZHfK7C4Rh8X"
      },
      "source": [
        "### KNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q55vzpI3Rh8Y"
      },
      "source": [
        "# Fitting classifier to the Training set\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "# Predicting the Test set results\n",
        "y_pred = knn.predict(X_test)\n",
        "# Evaluate the results\n",
        "from sklearn.metrics import accuracy_score\n",
        "score = accuracy_score(y_test,y_pred)\n",
        "print(\"Accuracy is \",round(score*100,2),\"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Avf3pP1oRh8Y"
      },
      "source": [
        "### Support Vector Machine SVM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kl0SxEERh8Z"
      },
      "source": [
        "# Fitting classifier to the Training set\n",
        "from sklearn import svm\n",
        "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
        "clf.fit(X_train, y_train)\n",
        "# Predicting the Test set results\n",
        "y_pred = knn.predict(X_test)\n",
        "# Evaluate the results\n",
        "from sklearn.metrics import accuracy_score\n",
        "score = accuracy_score(y_test,y_pred)\n",
        "print(\"Accuracy is \",round(score*100,2),\"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_6q2nCpRh8Z"
      },
      "source": [
        "### Decision Tree Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgBSBTVdRh8Z"
      },
      "source": [
        "# Fitting classifier to the Training set\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier()\n",
        "clf = clf.fit(X_train,y_train)\n",
        "# Predicting the Test set results\n",
        "y_pred = knn.predict(X_test)\n",
        "# Evaluate the results\n",
        "from sklearn.metrics import accuracy_score\n",
        "score = accuracy_score(y_test,y_pred)\n",
        "print(\"Accuracy is \",round(score*100,2),\"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KrqMoMgRh8a"
      },
      "source": [
        "### Random Forest Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndZ-k6FfRh8a"
      },
      "source": [
        "# Fitting classifier to the Training set\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf=RandomForestClassifier(n_estimators=100)\n",
        "clf.fit(X_train,y_train)\n",
        "# Predicting the Test set results\n",
        "y_pred = knn.predict(X_test)\n",
        "# Evaluate the results\n",
        "from sklearn.metrics import accuracy_score\n",
        "score = accuracy_score(y_test,y_pred)\n",
        "print(\"Accuracy is \",round(score*100,2),\"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O48QQbjcRh8b"
      },
      "source": [
        "# Market Basket Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rfMI6HWRh8c"
      },
      "source": [
        "# creating new data frame for market basket analysis\n",
        "aprior = order.copy()\n",
        "aprior.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJWnzB3LRh8c"
      },
      "source": [
        "# dropping unnecessary columns\n",
        "aprior.drop(['user_id', 'order_id','eval_set'], axis = 1, inplace= True)\n",
        "aprior.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9aDMK4mRh8d"
      },
      "source": [
        "# covert 'order_number' it to category \n",
        "def order_number_categorical(order_number):\n",
        "  if order_number in range(5):\n",
        "    return 'order_number_1-5'\n",
        "  if order_number in range(5, 10):\n",
        "    return 'order_number_6-10'\n",
        "  if order_number in range(10, 20):\n",
        "    return 'order_number_11-20'\n",
        "  if order_number in range(20, 40):\n",
        "    return 'order_number_21-40'\n",
        "  if order_number in range(40, 50):\n",
        "    return 'order_number_41-50'\n",
        "  if order_number in range(50, 70):\n",
        "    return 'order_number_51-70'\n",
        "  if order_number >= 70:\n",
        "    return 'order_number_70+'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd2Bgq4dRh8d"
      },
      "source": [
        "aprior.order_number = aprior.order_number.map(order_number_categorical)\n",
        "aprior.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3-K7oDZRh8e"
      },
      "source": [
        "# conver 'order_dow' to category\n",
        "def dowcat(dow):\n",
        "    if dow in [0, 1]:\n",
        "        return 'weekend'\n",
        "    else:\n",
        "        return 'weekday'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-Qo1AIKRh8e"
      },
      "source": [
        "aprior.order_dow = aprior.order_dow.map(dowcat)\n",
        "aprior.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAObqMxQRh8f"
      },
      "source": [
        "# converting 'order_hour_of_day' to category\n",
        "def hcat(hour):\n",
        "  if hour in range(7):\n",
        "    return 'early_hours'\n",
        "  if hour in range(7,10):\n",
        "    return 'hour_' + str(hour)\n",
        "  if hour in range(10, 18):\n",
        "    return 'peak_hours'\n",
        "  if hour in range(18, 24):\n",
        "    return 'hour_' + str(hour)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_5R84t6Rh8f"
      },
      "source": [
        "aprior.order_hour_of_day = aprior.order_hour_of_day.map(hcat)\n",
        "aprior.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFPIEnGoRh8g"
      },
      "source": [
        "# coverting 'days_since_prior_order' to category\n",
        "def intcat(interval):\n",
        "    if np.isnan(interval):\n",
        "        return 'first_order'\n",
        "    elif interval in [7, 14, 21]:\n",
        "        return 'interval_weekly'\n",
        "    elif interval == 30:\n",
        "        return 'interval_30+'\n",
        "    else:\n",
        "        return 'interval_others'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCz7neSmRh8g"
      },
      "source": [
        "aprior.days_since_prior_order = aprior.days_since_prior_order.map(intcat)\n",
        "aprior.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOJN4D7DRh8g"
      },
      "source": [
        "# Creating array to apply aprior algorithm\n",
        "aprior_array = aprior.to_numpy()\n",
        "aprior_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPA73HxMRh8h"
      },
      "source": [
        "# Taking first 5000 fields to calculate market basket to get rid of memory issues\n",
        "# Total number of orders: 499 Total number of products: 2809\n",
        "tdf = oproduct[['order_id', 'product_id']][:5000]\n",
        "n_order = len(set(tdf.order_id))\n",
        "n_product = len(set(tdf.product_id))\n",
        "print(n_order, n_product)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0WSQ6bWRh8h"
      },
      "source": [
        "# Counting product frequency based on product id\n",
        "pfreq = tdf.product_id.value_counts() / n_order\n",
        "min_support = 0.009\n",
        "paprior = pfreq[pfreq >= min_support]\n",
        "print(paprior)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb62p2rURh8h"
      },
      "source": [
        "# To see which order contains which product\n",
        "taprior= tdf[tdf.product_id.isin(paprior.index)]\n",
        "taprior"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izPFW1V7Rh8i"
      },
      "source": [
        "# Counting order size\n",
        "order_sizes = taprior.order_id.value_counts()\n",
        "order_sizes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ooq3GPSYRh8i"
      },
      "source": [
        "# filtering order size to minimum ordered items 2\n",
        "min_lenght = 2\n",
        "orders_apriori = order_sizes[order_sizes >= min_lenght]\n",
        "print(orders_apriori)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLK7JIRpRh8i"
      },
      "source": [
        "# taking out order id and product id for those customers who purchased more than 2 items\n",
        "taprior = taprior[taprior.order_id.isin(orders_apriori.index)]\n",
        "taprior"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcZbe8a3Rh8j"
      },
      "source": [
        "# Making product combinations for all orders to identify pattern\n",
        "transactions_by_order = taprior.groupby('order_id')['product_id']\n",
        "for order_id, order_list in transactions_by_order:\n",
        "  print('Order_id:', order_id, '\\nOrder list: ', list(order_list))\n",
        "  product_combinations = combinations(order_list, 2)\n",
        "  print('Product:')\n",
        "  print([i for i in product_combinations])\n",
        "  print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_31yODfRh8k"
      },
      "source": [
        "# Making combination of all orders min length will be 2 max length will be 5\n",
        "def product_combinations(tdf, max_length = 5):\n",
        "  transactions_by_order = tdf.groupby('order_id')['product_id']\n",
        "  max_length_reference = max_length\n",
        "  for order_id, order_list in transactions_by_order:\n",
        "    max_length = min(max_length_reference, len(order_list))\n",
        "    order_list = sorted(order_list)\n",
        "    for l in range(2, max_length + 1):\n",
        "      product_combinations = combinations(order_list, l)\n",
        "      for combination in product_combinations:\n",
        "        yield combination"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXL0No0lRh8k"
      },
      "source": [
        "# Counting frequency for all combinations\n",
        "combs = product_combinations(taprior)\n",
        "counter = Counter(combs).items()\n",
        "combinations_count = pd.Series([x[1] for x in counter], index = [x[0] for x in counter])\n",
        "combinations_frequency = combinations_count / n_order\n",
        "print(combinations_frequency)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kf6ueJBCRh8l"
      },
      "source": [
        "# filtering all combinations min_support = 0.01 and min_length = 2\n",
        "combinations_apriori = combinations_frequency[combinations_frequency >= min_support]\n",
        "combinations_apriori = combinations_apriori[combinations_apriori.index.map(len) >= min_lenght]\n",
        "print(combinations_apriori, len(combinations_apriori))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI-67AvrRh8l"
      },
      "source": [
        "# dividing all combinations into different columns\n",
        "product1 = []\n",
        "product2 = []\n",
        "product1and2 = []\n",
        "for c in combinations_apriori.index:\n",
        "  c_length = len(c)\n",
        "  for l in range(1, c_length):\n",
        "    comb = combinations(c, l)\n",
        "    for a in comb:\n",
        "      product1and2.append(c)\n",
        "      b = list(c)\n",
        "      for e in a:\n",
        "        b.remove(e)\n",
        "      b = tuple(b)\n",
        "      if len(a) == 1:\n",
        "        a = a[0]\n",
        "      product1.append(a)\n",
        "      if len(b) == 1:\n",
        "        b = b[0]\n",
        "      product2.append(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rORGH0fRh8m"
      },
      "source": [
        "# Putting into new dataframe\n",
        "apriori_df = pd.DataFrame({'product1': product1,\n",
        "                           'product2': product2,\n",
        "                           'product1and2': product1and2})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTuN72PfRh8m"
      },
      "source": [
        "apriori_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvgpvy0uRh8n"
      },
      "source": [
        "# Counting support for all products\n",
        "support = {**{x: y for x, y in paprior.items()},\n",
        "           **{x: y for x, y in combinations_frequency.items()}}\n",
        "support"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y8GHTgQRh8n"
      },
      "source": [
        "# Count lift and confidence for all combinations\n",
        "apriori_df[['support_1', 'support_2', 'support_12']] = apriori_df[['product1', 'product2', 'product1and2']].applymap(lambda x: support[x])\n",
        "apriori_df.drop('product1and2', axis = 1, inplace=True)\n",
        "apriori_df['confidence'] = apriori_df.support_12 / apriori_df.support_1\n",
        "apriori_df['lift'] = apriori_df.confidence / apriori_df.support_2\n",
        "apriori_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2lbN1TERh8n"
      },
      "source": [
        "# filter columns\n",
        "min_confidence = 0.2\n",
        "min_lift = 1.0\n",
        "apriori_df = apriori_df[apriori_df.confidence >= min_confidence]\n",
        "apriori_df = apriori_df[apriori_df.lift >= min_lift]\n",
        "apriori_df = apriori_df.sort_values(by = 'lift', ascending=False).reset_index(drop = True) #ordering by the lift\n",
        "apriori_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeq8bB-8Rh8n"
      },
      "source": [
        "# Converting product id to product names\n",
        "def convert_product_id_to_name(product_ids):\n",
        "  if type(product_ids) == int:\n",
        "    return products_name[product_ids]\n",
        "  names = []\n",
        "  for prod in product_ids:\n",
        "    name = products_name[prod]\n",
        "    names.append(name)\n",
        "  names = tuple(names)\n",
        "  return names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_EOvei8Rh8n"
      },
      "source": [
        "# Final combination of products with a greater likelihood of purchasing together\n",
        "apriori_df[['product1', 'product2']] = apriori_df[['product1', 'product2']].applymap(convert_product_id_to_name)\n",
        "apriori_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYyyYAkBRh8o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}